{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAABgCAYAAACHUNJuAAAcc0lEQVR4Ae2dCViU1RrH/wO4o4KKggKiIu5hrmVYmIpamajXpVwzMr1WZqltLuWSmV2tvPdKXc0yvUFlaNbNLSHBJcRlEEI2UUAwUXYInGHOfb6RYWaEYb4ZZjnDvPM8Ppzv+855z/v+znHeOd855z0SxhgDfYgAESACRIAIEAElAQfiQASIABEgAkSACKgJkGNUs6AUESACRIAIEAGQY6ROQASIABEgAkRAgwA5Rg0YlCQCRIAIEAEiQI6R+gARIAJEgAgQAQ0C5Bg1YFCSCBABIkAEiAA5RuoDRIAIEAEiQAQ0CJBj1IBBSSJABIgAESAC5BipDxABIkAEiAAR0CBAjlEDBiWJABEgAkSACJBjpD5ABIgAESACRECDADlGDRiUJAJEgAgQASJAjpH7PlCF0qyLOHHov/jy6FXIavRlkOfG4IvtYTibW1lzlxK8E6D25L2F+NeP+pDZ20g4XYM+vBK4y3Kiv2E7ti1hgc5g8N/C4ioU1cpWsuthC5gznNmDn1xicl5NIL00CFB7asCgpFEEqA8Zhc3AQjRiNPtPj4ZU0AQeATOxaOlbeH12f0AaC+l11eiwKbynrsZXi3qhVVPHhlRCZS1GgNrTYqgbbUXUhyzRtOQYLUG5oXVIOqDfCH8AKYjPKFJLc2SQFQ/CwqCeINeoxsJ9itqT+ybiXkHqQ2ZtInKMZsVrKuFN0dHHF164haQbBVAoxVahICYcPw5fhKndm5mqIpJjEQLUnhbB3KgroT5kzuYlx2hOuiaTLUHz9u7oilyk55cpHSO7dQwbQtti5QJ/tDRZPSTIMgSoPS3DuTHXQn3InK1LjtGcdE0o29G1I7oDKM8rQrksFd+ui8Kw9fPg70wvUU2I2WKiqD0thrrRVkR9yHxNS47RfGxNK9mpKVo4A7k3LuDA+9txddZyTO9OY0XTQragNGpPC8JupFVRHzJbw5JjNBtaEwt29YBvJwAHTyA9YCVWPNwBEhNXQeIsSIDa04KwG2lV1IfM1rDkGM2G1gyCHSZgzYHPsXq0J5zMIJ5EWpgAtaeFgTfC6qgPmaVRJcK+R7NIJqGmJcBKkX29Eu4+7ckpmpasdaRRe1qHe2OqlfqQ2VqTHKPZ0JJgIkAEiAARsEUC9CrVFluNdCYCRIAIEAGzEeDAMVJAXLO1LgkmAkSACBABgwlY2THKkBvzHfbu34X1z87Ccyt/QHylaspThpyTu7H0lRfw9++uoMpg06gAESACRIAIEAHDCVjZMdpSQNws/DDPFxKJRNQ/34/OQ254e1i5hD3YaGXEVL0ZCFC/NQNUuxbJyeKbSmR8/Ty6z03A0sNH8PE4YcMeAJaB8NmbcHf9dsyheKB23VHJeCJABIiApQhwsh1OFRD3RHWQ7E5wgDpI9n8akVMURpy8fMy1U4cnG3lhTXqYjgD1W9Ox5EmSudrVGBs5cYy1A+JKVEGyP2tcQbJ5anxjOoyYMvZgoxgOlMe2CFC/ta32Mqe2Vp5jVJvGf0Bce5jHsAcb1X2OUo2FAPXbxtKSvNjByRwjgLyfsKj7RHw2aQu+6pmJG0Fr8CbFA+Wln1hMj5UrV1qsLqrIdgi4uLjg7bffth2FSVObJsDJq1QAmgFxhXigduAUhbk41esbzbQhPUqznGbaEBm85D137hy2bNmC4OBgXlQiPTgh4OXlxYkmpIYmAVaajt9iZRjyeG84azxgucex83IfhAR1gQQM8rzLOBGVhILm3hg2ahi6cX5cHj+OUYBKAXE1upb9JePi4uDu7o6IiAj7M54sJgI2RaAKBefDsHnzFmxusQY5Wo6xEhnHz8JxeIDyBCCW+xNenfcDXMd4IPP7FVj9wyb8tONZ+DXnZyHi/ej5cYyOvTDz6Nc6gmQzyG+n4Oz5eKSU9cL0pzsgIfwgpB2CMG9cDzRHFUozzuDnI3H4s9VATJw8El4VyYg+exnXMQDTAx0Q+f01dBvrg/yEy0iT9cOUwcU49H0qvP82HQGtM/C/fdFgo57BU36av3vux0XX5iRw4cIFDBo0yJxVkGwiQARMQsARroNnYOnMaGw+eJ9ARQaiTnkhYFZzAJW4FpOPKWE78Xg7B8j/1g+z/Xfix5cmYflgfr9r+XGMEmd4+tQDqklzlJ/7N3a3fgntthxDuUsGNoZKMHJMJzgd2IRNlwPx/qrFkO1/CU9+6IBT6wahzZVl+C+bh9bp57B7twuWj/ZFWcyn+LxyIoqSHXH71y9x0KkFMstuICfta3xTOQwT/PzheF8706VlCCQnJ2P8+PGWqYxqIQJEwCwEFGm/I3bYcMxXLu1shm7T5qFbdU1OXXpgQAc3tGvNj+upCwI3q1LrUk59TwKn1n8hOzoLZSdS0HJ+CIY0u4224x9Ax4TdeOldB8x55XF4ODmhRasWuJaSi6KqbEiPZaDwjwr4Pv8Rfrq0FoGdK5AVlQ25rDcmL3oUbXNKkR3/F/wXPgnv4tYY278LOUU1dIunoqOj0bdvX4vXSxUSgXoJyLMReSAOBfVmaowPK5AaGYNMuSpMpxgbK5AWk45hAT6o7VwYZOnxiJswBxN6CqNJfj+1dedUV5YtxfHT3pi4PARjO+UiJrwAM0d3QtL+b3BlchCGtxPGeSVIlybA088DbW5IcfzcICxYPh3+1RO9ivRYRCSOw+vLguCedhYR6SMQsmwq+hWex8GYhzFuSDtOrW/8aqWlpSmNHDJkiAHGCpP68Tj6XTjCD51BRikvEXV51csAtBbNyjEvVgjpjnXYW9lWa3GJRfFYrTJHOJcdwtKPY1Es1jcqriEmtgcCfOtwfPJrOPR1ERatDoIHv9OLSto24hjlyIs/g5hpL+HFADewtNMIzxmMns4FyCt2xKiBPmglRJDLOYHPw3rj3fkDUSnknzEbU/qqXs/eRfbFU0iaNxljvYBr56ORETIXwT2dkHXmKGKCfdHizyKIbX+r9dVGWrGw8Eb4eHp6irZQOak/axuiM6T43/oZGPdyGFIqrN+CvOolGqyFM/LLqwrF57/EmxfHYO1UXzSxMBfrV9cEHuMXYmbiB/hHTJ6o70bVa1Tf+z0LK0LC3oMomb0QQR7NrG+aHg3uV19Pdis9Zn8i9mcpnpwyHB4SOf5MiMVRl0KU3u2KwBlP4+b3ETh+5mf8c0scAnavxdRu5bj46x948skH4ab6ZcLyEB+VjWcmDkY7dg0x4UVYMmM42kmKkXYhCR1LKiFxaa1cRWUlK+262qSkJIwZM8YABupJ/fUrN2JX2CYM+n4nfkwsM0CGObLyqpc5bDWFTI55yZLx/YbfMHrJOHg7qb5ITGGzDclw6o6JLwXg+EcR+EPvj04dr1FZERK/2Yf4oc9hbr+2kMizEXU0EeU8Y2A2+FGU3GAZeRU1mitKMpk0OY/Jau4YklAwWd51llUiN6SQSfIKg1zVRzOtuifmr2Y5zbSYsjzlGTNmDFuyZInxKlWcYRt8prFdyX8ZL8McJXnVyxy2mkImN7zk7M6vq1j/4D0svcoUhtmwjKoUtic4gL16OJcpasxQMNmtiyz8jSCGwLdY+KU/mawqie1auu8+XiUsec+LrCeUA07hdQ4D+rNFh7I1ZNUI5SZhGyPG+35ZSJw7w6eDejgucfbCA34dYNw6JwmcOnjDk5sNp/Z5cHNCQkIDtmrwOqnPq173/Yfi5pIjXuwGovb+jM4Th8LHot+Swta0ZMQc+Q5f/BCPUnkOzu7bgc+OpKPCWu3k4I2AKV2xM/QYMhQqJSRwchuI6R8cAYt8H9P9O8JJ4YbHlz+Nblq8nOE3JxQpjCmDmQgBTRi7jB1PCRv/+f1omcCvmvaimX0e3Jyfn4+bN29i6NChxjU0r5P6vOplHGXzl+KIlyLjN3z9nTcmP+Rda3Vl1R+hGCnyXFYhGpXef+O+QEqNwwGg2pqWlYrjW77B1eJEbNxwDFettrasGboOfxwjDhzA0Sv1TFU4tYePpzPXDk9sJzZukCVWOuUzkED1wc2PjIRn8m+ICo2F9HolBvsJK7yawnvqany1SIptTRvXTkthtCh8fH19DeQlvJhRT+pP5mlSn1e9DCdsmRJc8bqL7HNROO46EK91bVHLfsc+z2BH6Ck8umhv9RaOQKwMW4fpvi1r5dV5Q5aP1OgwbF33Bc6l56NEcIzKYYrG1rTmKWgZ+nf0/eVFtB3vDx8r/rd36NoXj/qsQsTZLCzs27vWjwWddtrqA25e6tqhIppzgpppxirY1T2zGODPlh6+qSajuMrCnn2B7UlXz69qltNMqwvxn9q4cSPz9fU1XFFFIUvY9y+2L6Hw3nyFLItFHklgZaIlZbL9cwezufszRZcQlZFXvUQpX18mXnnVp7MRzxTX2f75PRlmhLFM9aSatiBZJjv8RmD1nBmY89ht7FyRoesUKtmt3zaxUT5r2clSdUWK62HsGedRbM3JW0whzNsFBbENZwq067f41Q126MXeDEG7WLIdzLnSq1Quf9GoDm6+VX1ws6Ck+uDmqY3o4GbBssTERAwbNkyjJcTMs95Byt43MHnWEszq7wIH4ZVVkwkIv+uC2r/xNUQ3KMmrXg0yykyFxbCqBFBqhXbUY3JBEk4eTIXPgK7oqGsizMkLQas+wqdP+yiFlR5bjTlrf0GOQZvhm8Jt5Hy8EVyOvGLVe1JdW9PKrDfHqLSwDTx83YHTl5ByR6WrHo42/JgcI5eNV/vgZqY6uHlB4zq4WcAfGxuLwYMHV7eE2HnWbPSw6KQ+r3rx2IHFsrqCKvC2OIOhMuMyogq84O/dAU3rwStxHoTFO7bj1d7CXulSXPn4ZSzecQGlhmyllbRH34c6oqyi2tno3JrWAurlhvUoZbZHzdG5ey+gNA6xV4rMVgsvgskx8tIS9+nB/8HN9yncgEsh6o3aMVbPsy59C6/P7g9I782z3hOvmmfthVYWn2flVa8GgDdbUVtmdRc5f1yCFK3g7tpSz0ISCZw6T8B7X6/HWGUckWv48ZXl2HA0C3LRbJvAc9wMjHStnkCUdMFTOyKrV206wT1oDTIitmHBoHZ6dBFdoZEZHdHGzR1euIbfU29Bc62QkQK5LkaOkdfmcWqKFs5A7o0LOPD+dlydtRzTuxswuc+rXffpJZzBKHwGDBig/UTSAf1G+ANIQXyGxi9URwZZ8SAsDOppnbi2HOrFCmIR+twojFhcR+QfWTp+emsyhkz6ECdyhVeXGh9h4/XXr2DEiIUIjbsjKrKJRmn9SQ5Z6Ve6DNmpVwG4w9ejjf7scESbIYuw86ul6KnMHYXNz7yNXQnio2hJXLzg41L3Osj7t6aJUMhMWSRo1tIZTZGLy8k5KDVTLdyItfgcLlVYQ0BzsYxmWplBFse29ACD8wS25niWzuAFmuU00zWVcJ7YtWsXc3d3r0NLBSs9uZZ5wYMF7Upi9+b75Sz/5Cb27CfnDVhgoxItLBzpUbNYQmCl+1+Pehbk8KeXLG4L66G0Zzz75FKpyuB7f3P2s7nKZ73Zi4duaD+TX2KfPOjMAGf24CeXmPbSEVPwMjUrbfXNc6WyexLbkSh+GRdT5LHTG59kztX9ynnUenY8R71Izjy6Wliqqi/ZwQIcdegVCzOm6pjyi1nFoZZTExxjz/qdolBWs5w6LUSlkLIj34axsB9Ps6tWiOqjskv4u3XrVnbx4kXNWzXpkJAQ9sQTT9RcaybkiTtYAMB6bIlT/jBQ/PkLe+3Zf7NLJrPHuFWW3Okly2YnQ9ezNaEnWY5MvbpRyVJRyBL3f8RWvx/BEmtxq2A5J3eyNWt2spOivsQN52V+Vpo9xgRp1Q9SvMj25xgYS+tuCgt77sHqH1zOrOf8vSz5r/vawwQqWk2EyjH6bGRnKhqRXXUArXv8zs141o4Vqffg5vq58HJitrBxPzg4GMJxUoGBgYiMjKyluHAG46OPPlrrvnBDNc+anleEclkqflkXhWHr19ScllJnIQvc5E4vpy4Y+eIqjKzLdklb9J3yOtbV9QzN4DHyebxXZ8E6Cxh8kztW+iwoL0KesUE8m/TE9M1bkXRtLt6LzELql29hUdcuCF8bqI7ZrK9+kz4XVgbHI/ZSEjKbPYRZQd2rA6EzyHNPYc/32ej7t8l4SOz+32at4OoK4FomcvKrAI/G6z5ojtGkHdGEwpQHN7c3IswdH0GZBafYu3dv+Pj4KDfuR0VF4dSpU7UACU6zf//+te4rb+iZZ2Wl6Yg6ccXy8x316sXxEUp1Uzbv3XpZmbdqo6SXFeJmrlEllYUkbo/hzdBNmN9TWI2Thcj3XsMb36ZCZrxII0sasjJYZBVtOsBTeTJfqXoVrciitpaNHKOttZhefe+dmP248nxKCax1Yna7du1w6NAh7NmzB+vXr1dqvW6d9rglOztbeX/QoEF1W+XqAd9OAA6eQHrASqx4uEP1yrwqFJzfh7cWTMWor/5ASd2lzXdXp14Av0comQ9HvZLrYVVvOWs/9PFGZ+X/IUMVkaC53wx8uPMtjFKuVL2I3SHLsOXMbdMvbqpXNXOuDL6BP/Mt7+rrNdfED8kxmhgoX+KsG5R5+PDhShyTJk1SjhqPHj2qNWo8f/688rmfn59ubA4TsObA51g92lNj9OwI18EzsHTmQ7rLmftJnXrxMVo3t+kGy6+TlcFSLFKg6lY2Lgs1OTZFE0ddu/v1qeIEt5FLsP2TF+6tVC2Nx/HIKygUZh8t/bHJlcGWhlS7vsb7kri2rfZ3pyYo8zyrnpjdokULrF69GvPmzUN4eDgeeeQRZVtcuHABQ4YM0d0uDZhn1S1U84kXpnwVhymat8Skdep1b7TerVqG8aN1I/USo3uD8hihl05WgiLCSRIpOHs+HillvTD96Q5ICD8IaYcgzBvXA3WcAd8g7cUUZvK7KBaTUV8eSVv0m/Mq3vzxBD5otxE7VzwCV2P9rL666n2uiqJ1ojqKVic4aETR+k8ji6JVLwoDHtKI0QBYNpVVIygzDydmT5s2Dd7e3ti+fTtSUlKUKOPi4jBw4EDdWI2eZ9Ut0iRPROll3dG6Sew0hRB9rDg7ScKhdTv0MIXdqETOkS+xrXgBdm6eiu5NrOIVAdhXFC2TNJ0qnruphJEcTghweGK2MGpctWqVElBoaKjyrzBi9PcXNvE3wk/NaD3IqqN1vslqnCRxIgUt54dgSLPbVj1JwqG1C9wFaOX5KCo3Nr5LFUqlu7B4RSGWbV+CkW7WfTGnWhlcXr26+1vl6u55Vl/dzXPfpBEjz61jlG4cBmWutmP27Nlwd3fHtm3bcOnSJeUZjI899phRVnJdiLPROs+sWLYUx097Y+LyEIztlIuY8ALMHN0HVo/xlJuPwjJjHKOwFeIYNrxwAH0+Xo25/dpaOZQbAH0rg6uu4IsJo/DGiVs8dxWL6kaO0aK4tSu7tz//3j3NtHau+q80y91L8xaUWa2/MGpcsWKF8sb8+fOVf406g1Etkr8Uh6N1/iCpNOLwJIlqJ6LS0OC/FUn45u2NSJqzCauCvDQWjBksyXQF9K0MduyGif/4BIuHtRdZZy9072yNGWCR6pkgGzlGE0AkEeIJLF68GC4uLpBKpcqVqoKzNPwj7BVMQHRsBpAZh2jpLQOCNhtem/gS/I7WxdtgwZw8niShciLGYGA3cfKDlfjQ5Q3sWDwIztaaVqxLd10rg+W3ID36Mw5Hp6FI39i2+Day8wE4N0VTJ56Mq8vgBt6rIxoO3SICZiXwzjvvKMNmBQcHm7UeEm5bBBQlN1hGnpXjiyoPBvZggIGxUlkZSw9bzHobdWBxw9pJUZLGIn9NYiW6xChKWFbGbR3xlhWs4sxG5iMm/qkqJFyPLSzOwGh5ulTj9T6NGBv4w4KKG05AGDUKn6FDhxpemEo0WgJcnCTh4IoufToCKELpX2LnGKtQHPc5Fr0LvBu6EEPaVB8hZUBLsaJMpOZpnH4iat5PZKCLelcGl+FKbCw8Jw9DDz3egMllUGo4xAsdDTfRABrWz6oHhfUVJA0aH4EuXbpAiJG6bNmyxmccWWTjBFrDq7cPgAJk3y4TYQuDPOcXrH0uEoFfrDPyaDg58qLDcDhH4xRHUfN+Jgh0ocjG+Z/vYtJQb73HuFXdykIcAC+/zmjXyN+kkmMU0fUpi+kJCNFujJtfNL0uJJEIqAk0h6dfX3igCDcL/9Ibxo2VXsCOxZtRuHITXqsJWaiWJiolv47I/TfRpWOze9kNmfcTVYHuTIq00wjPeRj9m+fjTr2ReRQoL8pHOXwwop+X9VcN6zbJJE+su8HGJCaQECJABIiAqQg4oHW3PhiGa4jLuoMq+OheWSrPwtENqxAxcA32PdPHqEg9rOIaTmxdicXRD+OYar+jkxt6t7mC4B/ccWRBGsJf3oT/Fdd+reswIARblz/cAMOrcCflEk43+wtP5TfBmHpHgVUoyruJXPgjcEBHfct0GqATH0XJMfLRDqQFESACnBCQeD+I8QGu+DUtFwUA3OrSS9iWs2c9Xv4XMPnjQpz5MaKuXDruMcgKbyAt+TyO7/8BUemlwNxZ6Fzzbaya99uAHk384Ld9N2bokATIYfxhII5wG78Wlwc2Q1dPZz3Orhw30lIBr9Ho19WYleQ6DeDyQU1TcKkdKUUEiAARsDQBR08MHO+P0v1XkVMFuNVaaCLMCf4LLy/9D1JLgQ9DDjdYQx9h3k4lRTXv9743HFkepL+cQnpFHSNGtwcxfqSXqpRxf53aw8dTRFFWgOuXs+HxzKPwb1Xv0FKEMP6z0Bwj/21EGhIBImBRAm3xwOgg9L8Yi/hMjZWi1TooMg/izZBNiCw1lVI+GO7rjqYq+aLn/UxVvwg5JVdx4aQzJo3shdYistt6Fhox2noLkv5EgAiYmIAELR8IxMz+4TideBuzu3XRes0o6TgaG39LwQaT1SpBk9bqs0a15v0c3ND+iWDUHVFYCHQh1Qh0EYAp/h11z4karS9DZeoFHMEEbB7hrsXCaJGcF5QIGyw515HUIwJEgAhYmEAZ/gidiwDpc7jy76fQ0ZJvD+V3cO2mmHk/SyEphfTTWZhd8iZ+f+fhRr8iVaBKr1It1beoHiJABGyIQCv0eXoWgg9GIDLrrmX1Vs776VsMY0GVypNwLLwNlk3ztwunKJAlx2jB/kVVEQEiYDsEJJ3H480Nd/Hpt1KU247aJtZUhpzDexAxJgSTe1r9zBMT26ZbHDlG3WzoCREgAnZNoCX8nl2BOTH/xJ5Ek620sSmi7Nav+Oiz9lj/0iNwteTrZCtTIsdo5Qag6okAEeCYQPMBeH7rEzi38zfkcaymeVQrQ3zE7+i/dRlGqYIPmKci7qTS4hvumoQUIgJEgC8CVSgrLEMzlzZmWPHJl6Xa2tir3QA5Ru2eQFdEgAgQASJg5wToVaqddwAynwgQASJABLQJkGPU5kFXRIAIEAEiYOcEyDHaeQcg84kAESACRECbADlGbR50RQSIABEgAnZOgByjnXcAMp8IEAEiQAS0CZBj1OZBV0SACBABImDnBMgx2nkHIPOJABEgAkRAmwA5Rm0edEUEiAARIAJ2ToAco513ADKfCBABIkAEtAmQY9TmQVdEgAgQASJg5wTIMdp5ByDziQARIAJEQJsAOUZtHnRFBIgAESACdk6AHKOddwAynwgQASJABLQJkGPU5kFXRIAIEAEiYOcEyDHaeQcg84kAESACRECbADlGbR50RQSIABEgAnZOgByjnXcAMp8IEAEiQAS0CfwfFt7LCYbT8QEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理基础\n",
    "\n",
    "## 自然语言概念\n",
    "自然语言，即我们人类日常所使用的语言，是人类交际的重要方式，也是人类区别于其他动物的本质特征。  \n",
    "我们只能使用自然语言与人进行交流，而无法与计算机进行交流。\n",
    "\n",
    "## 自然语言处理\n",
    "自然语言处理（NLP Natural Language Processing），是人工智能（AI Artificial Intelligence）的一部分，实现人与计算机之间的有效通信。  \n",
    "自然语言处理属于计算机科学领域与人工智能领域，其研究使用计算机编程来处理与理解人类的语言。\n",
    "\n",
    "## 应用场景\n",
    "自然语言处理，具有非常广泛的应用场景，例如：\n",
    "* 情感分析\n",
    "* 机器翻译\n",
    "* 文本相似度匹配\n",
    "* 智能客服\n",
    "\n",
    "## 通用技术\n",
    "* 分词\n",
    "* 停用词过滤\n",
    "* 词干提取\n",
    "* 词形还原\n",
    "* 词袋模型\n",
    "* TF-IDF\n",
    "* Word2Vec\n",
    "\n",
    "说明：  \n",
    "scikit-learn库中实现的tf-idf转换，与标准的公式略有不同。并且，tf-idf结果会使用L2范数进行规范化处理。\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where': 8, 'there': 5, 'is': 0, 'will': 9, 'way': 7, 'no': 2, 'royal': 4, 'road': 3, 'to': 6, 'learning': 1}\n",
      "[[2 0 0 0 0 2 0 1 1 1]\n",
      " [1 1 1 1 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 对语料库中出现的词汇进行词频统计，相当于词袋模型。\n",
    "# 操作方式：将语料库当中出现的词汇作为特征，将词汇在当前文档中出现的频率（次数）\n",
    "# 作为特征值。\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "# 语料库\n",
    "docs = np.array([\n",
    "    \"Where there is a will, there is a way.\",\n",
    "    \"There is no royal road to learning.\",\n",
    "])\n",
    "# bag是一个稀疏的矩阵。因为词袋模型就是一种稀疏的表示。\n",
    "bag = count.fit_transform(docs)\n",
    "# 输出单词与编号的映射关系。\n",
    "print(count.vocabulary_)\n",
    "# 调用稀疏矩阵的toarray方法，将稀疏矩阵转换为ndarray对象。\n",
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53594084 0.         0.         0.         0.         0.53594084\n",
      "  0.         0.37662308 0.37662308 0.37662308]\n",
      " [0.29017021 0.4078241  0.4078241  0.4078241  0.4078241  0.29017021\n",
      "  0.4078241  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 将词袋模型转换为tf-idf值。\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XX评论情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目背景\n",
    "公司活动，新闻，微博，影评，商品评价等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>此英雄完全自给自足，没有任何超能力，自己造就自己，酷！科技以人为本，发展才是硬道理！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>如果一个男人嫌女人太聪明了，那一定是因为他自己还不够牛逼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>这是一个会搞笑，爱臭屁又喋喋不休的英雄噢！结尾那句“I am Iron Man”太帅了~~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>没想到会比这侠那侠的都要好看！2个多小时的片子并不觉长，紧凑，爽快，意犹未尽……</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>想起一个人，铁臂阿木童.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                         comment\n",
       "0   pos      此英雄完全自给自足，没有任何超能力，自己造就自己，酷！科技以人为本，发展才是硬道理！\n",
       "1   pos                    如果一个男人嫌女人太聪明了，那一定是因为他自己还不够牛逼\n",
       "2   pos   这是一个会搞笑，爱臭屁又喋喋不休的英雄噢！结尾那句“I am Iron Man”太帅了~~\n",
       "3   pos        没想到会比这侠那侠的都要好看！2个多小时的片子并不觉长，紧凑，爽快，意犹未尽……\n",
       "4   pos                                    想起一个人，铁臂阿木童."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r\"movie.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺失值探索。\n",
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    11628\n",
       "neg     3943\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 异常值探索。\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重复值\n",
    "# data.duplicated().sum()\n",
    "# data[data.duplicated()]\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转换\n",
    "将label与comment列转换为数值类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"] = data[\"label\"].map({\"pos\": 1, \"neg\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11555\n",
       "0     3928\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我们', '来', '学习', '自然语言', '处理', '。']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "# list(jieba.cut(\"我们来学习自然语言处理。\"))\n",
    "jieba.lcut(\"我们来学习自然语言处理。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于进行中文分词的库。安装：\n",
    "# pip install jieba\n",
    "\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "# 获取停用词列表\n",
    "def get_stopword():\n",
    "    # 默认情况下，在读取文件时，双引号会被解析为特殊的引用符号。双引号中的内容会正确解析，但是双引号不会解析为文本内容。\n",
    "    # 在这种情况下，如果文本中仅含有一个双引号，会产生解析错误。如果需要将双引号作为普通的字符解析，将quoting参数设置为3。\n",
    "    stopword = pd.read_csv(r\"stopword.txt\", header=None, quoting=3, sep=\"a\")\n",
    "    # 转换为set，这样可以比list具有更快的查询速度。\n",
    "    return set(stopword[0].tolist())\n",
    "\n",
    "# 清洗文本数据\n",
    "def clear(text):\n",
    "    return re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\", text)\n",
    "    \n",
    "# 进行分词的函数。\n",
    "def cut_word(text):\n",
    "    return jieba.cut(text)\n",
    "\n",
    "# 去掉停用词函数。\n",
    "def remove_stopword(words):\n",
    "    # 获取停用词列表。\n",
    "    stopword = get_stopword()\n",
    "    return [word for word in words if word not in stopword]\n",
    "\n",
    "def preprocess(text):\n",
    "    # 文本清洗。\n",
    "    text = clear(text)\n",
    "    # 分词。\n",
    "    word_iter = cut_word(text)\n",
    "    # 去除停用词。\n",
    "    word_list = remove_stopword(word_iter)\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "# 对文本数据（评论数据）的处理。步骤：\n",
    "# 1 文本清洗。去掉一些特殊无用的符号，例如@，#。\n",
    "# 2 分词，将文本分解为若干单词。\n",
    "# 3 去除停用词。\n",
    "\n",
    "# 以上步骤通过调用preprocess方法来实现。\n",
    "data[\"comment\"] = data[\"comment\"].apply(lambda text: preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             英雄 自给自足 超能力 造就 酷 科技 以人为本 发展 硬道理\n",
       "1                        男人 嫌 女人 太 聪明 是因为 牛 逼\n",
       "2    这是 搞笑 爱 臭屁 喋喋不休 英雄 噢 结尾 那句 IamIronMan 太帅\n",
       "3         没想到 这侠 那侠 要好看 小时 片子 不觉 长 紧凑 爽快 意犹未尽\n",
       "4                                   想起 铁臂 阿木童\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调用cut方法可以对文本进行分词，返回结果。cut方法返回的是生成器对象。\n",
    "# jieba.cut(\"今天我们学习自然语言处理。\")\n",
    "# lcut方法返回的是列表。\n",
    "# jieba.lcut(\"今天我们学习自然语言处理。\")\n",
    "data[\"comment\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用TfidfVectorizer来进行文本向量化，具有一个局限（不足）：就是语料库中存在多少个单词，就会具有多少个特征，\n",
    "# 这样会造成特征矩阵非常庞大，矩阵非常稀疏。\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(data[\"comment\"].tolist()).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8405959352394075\n",
      "0.672436063032808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.51      0.45      1004\n",
      "           1       0.81      0.73      0.77      2867\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      3871\n",
      "   macro avg       0.60      0.62      0.61      3871\n",
      "weighted avg       0.70      0.67      0.68      3871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"comment\"], data[\"label\"], test_size=0.25, random_state=0)\n",
    "# TfidfVectorizer可以看做是CountVectorizer与TfidfTransformer两个类型的合体。\n",
    "tfidf = TfidfVectorizer()\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "# lr = LogisticRegression()\n",
    "steps = [(\"tfidf\", tfidf), (\"model\", lr)]\n",
    "pipe = Pipeline(steps=steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2867\n",
      "0    1004\n",
      "Name: label, dtype: int64\n",
      "1    2585\n",
      "0    1286\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_test).value_counts())\n",
    "print(pd.Series(y_hat).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9886324491904926\n",
      "0.706277447687936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.22      0.28      1004\n",
      "           1       0.76      0.88      0.82      2867\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      3871\n",
      "   macro avg       0.57      0.55      0.55      3871\n",
      "weighted avg       0.66      0.71      0.68      3871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\")\n",
    "# rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "pipe.set_params(model=rf)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9711505339304168\n",
      "0.7075691035908034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.27      0.32      1004\n",
      "           1       0.77      0.86      0.81      2867\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      3871\n",
      "   macro avg       0.59      0.57      0.57      3871\n",
      "weighted avg       0.68      0.71      0.69      3871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "b = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, n_jobs=-1)\n",
    "pipe.set_params(model=b)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7695487426799862\n",
      "0.7377938517179023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.13      0.21      1004\n",
      "           1       0.76      0.95      0.84      2867\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      3871\n",
      "   macro avg       0.62      0.54      0.52      3871\n",
      "weighted avg       0.69      0.74      0.68      3871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
    "pipe.set_params(model=ada)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
